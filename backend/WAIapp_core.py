# backend/WAIapp_core.py

import os
import pandas as pd
import numpy as np
import warnings
from dotenv import load_dotenv
from volcenginesdkarkruntime import Ark
import markdown2
import json
from pandarallel import pandarallel

# åˆ†æåº“
from sklearn.cluster import KMeans, MiniBatchKMeans
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dense, Input
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from pandas.errors import SettingWithCopyWarning, DtypeWarning
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth

# å¯è§†åŒ–åº“
import plotly.graph_objects as go
import plotly.express as px

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# (å…³é”®) è§£å†³ KMeans å†…å­˜æ³„æ¼è­¦å‘Š
os.environ['OMP_NUM_THREADS'] = '1'

# åˆå§‹åŒ– pandarallelï¼Œç¦ç”¨è¿›åº¦æ¡ä»¥ä¿æŒæ—¥å¿—æ¸…æ´
pandarallel.initialize(progress_bar=False) 

# æŠ‘åˆ¶ç‰¹å®šçš„Pandasè­¦å‘Š
warnings.filterwarnings('ignore', category=SettingWithCopyWarning)
warnings.filterwarnings('ignore', category=DtypeWarning)

# ==============================================================================
# AI Agent æ¨¡å—
# ==============================================================================

def get_ark_client():
    """è·å–å¹¶è¿”å›ä¸€ä¸ªé…ç½®å¥½çš„ Ark å®¢æˆ·ç«¯å®ä¾‹"""
    api_key = os.getenv("ARK_API_KEY")
    if not api_key:
        raise ValueError("ARK_API_KEY not found in environment variables.")
    return Ark(api_key=api_key)

def generate_full_report_stream(user_profile: dict):
    """ã€æ ¸å¿ƒã€‘ç”Ÿæˆä¸»å¸‚åœºåˆ†ææŠ¥å‘Šçš„æµå¼å‡½æ•°"""
    ark_client = get_ark_client()
    market = user_profile['target_market']
    categories = user_profile['supply_chain']
    seller = user_profile['seller_type']
    price_range = f"${user_profile['min_price']} - ${user_profile['max_price']}"

    system_prompt = f"""
    ä½ æ˜¯ "WeaveAI" åº”ç”¨å†…çš„ä¸€ä½é«˜çº§æˆ˜ç•¥é¡¾é—®ï¼Œä½ çš„æŠ¥å‘Šæ˜¯ä¸ºä¸€ä½è®¡åˆ’è¿›å…¥'{market}'å¸‚åœºçš„'{seller}'ï¼Œä»–/å¥¹ä¸“æ³¨äº'{categories}'å“ç±»ï¼Œç›®æ ‡å”®ä»·åœ¨'{price_range}'ã€‚
    ä½ çš„æŠ¥å‘Šå¿…é¡»ä¸“ä¸šã€è¯¦å°½ã€æ•°æ®é©±åŠ¨ï¼Œå¹¶ä½¿ç”¨ç²¾ç¾çš„Markdownæ ¼å¼ã€‚

    **ç¬¬ä¸€é˜¶æ®µï¼šè¾“å‡ºæ€è€ƒè¿‡ç¨‹**
    åœ¨æ­£å¼å¼€å§‹æŠ¥å‘Šå‰ï¼Œä½ å¿…é¡»å…ˆè¾“å‡ºä½ çš„æ€è€ƒè¿‡ç¨‹ã€‚è¿™éƒ¨åˆ†å†…å®¹å¿…é¡»ä»¥ "æˆ‘éœ€è¦..." æˆ– "é¦–å…ˆ..." å¼€å§‹ï¼Œæ¦‚è¿°ä½ å°†å¦‚ä½•ä¸ºç”¨æˆ·åˆ†æã€‚ä¸è¦ä½¿ç”¨ä»»ä½•Markdownæ ‡é¢˜ã€‚
    
    **é‡è¦æŒ‡ä»¤ 1ï¼š** åœ¨æ€è€ƒè¿‡ç¨‹ç»“æŸåï¼Œä½ å¿…é¡»å¦èµ·ä¸€è¡Œï¼Œå¹¶åªè¾“å‡º `<<<<THINKING_ENDS>>>>` è¿™ä¸ªç‰¹æ®Šæ ‡è®°ã€‚
    
    **é‡è¦æŒ‡ä»¤ 2ï¼š** åœ¨ä¸Šä¸€ä¸ªæ ‡è®°ä¹‹åï¼Œä½ å¿…é¡»ç«‹å³å¦èµ·ä¸€è¡Œå¹¶è¾“å‡º `<<<<REPORT_STARTS>>>>`ï¼Œç„¶åæ‰èƒ½å¼€å§‹ç”Ÿæˆä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹Markdownæ ¼å¼çš„æ­£å¼æŠ¥å‘Šï¼Œä¸­é—´ä¸èƒ½æœ‰ä»»ä½•å…¶ä»–æ–‡å­—ã€‚

    **ç¬¬äºŒé˜¶æ®µï¼šè¾“å‡ºæ­£å¼æŠ¥å‘Š**
    ---
    
    ## æŠ¥å‘Šæ‘˜è¦ (Executive Summary)
    *   åœ¨æ­¤å¤„ç”¨2-3ä¸ªè¦ç‚¹ï¼Œ**åŠ ç²—**æ ¸å¿ƒå…³é”®è¯ï¼Œé«˜åº¦æ¦‚æ‹¬æ•´ä¸ªæŠ¥å‘Šçš„æ ¸å¿ƒå‘ç°å’Œæœ€ç»ˆå»ºè®®ã€‚
    
    ---
    
    ## ğŸ¯ å¸‚åœºæœºé‡æ´å¯Ÿ (Market Opportunities)
    
    ### ä¸€ã€ å®è§‚ç¯å¢ƒåˆ†æ
    1.  **å¸‚åœºæ½œåŠ›ä¸è¶‹åŠ¿**: ç»“åˆ**é‡åŒ–æ•°æ®**è§£é‡Šå¢é•¿ç©ºé—´ (å¿…é¡»æ³¨æ˜æ¥æºå’Œå¹´ä»½)ã€‚
    2.  **æ–‡åŒ–ä¸æ¶ˆè´¹ä¹ æƒ¯**: ã€æ ¸å¿ƒã€‘æ·±å…¥åˆ†æå½“åœ°æ–‡åŒ–ã€èŠ‚å‡æ—¥ã€ç”Ÿæ´»æ–¹å¼å¦‚ä½•å½±å“'{categories}'å“ç±»çš„æ¶ˆè´¹åå¥½ã€‚
    3.  **æ³•å¾‹æ³•è§„ä¸å…³ç¨**: ã€æ ¸å¿ƒã€‘æ˜ç¡®æŒ‡å‡ºè¿›å£é™åˆ¶ã€æ‰€éœ€**å…·ä½“è®¤è¯** (å¦‚CE, RoHS) å’Œå¤§è‡´çš„å…³ç¨ç¨ç‡ã€‚
    
    ### äºŒã€ é«˜æ½œåŠ›ç»†åˆ†å“ç±»æœºä¼šç‚¹
    *   ä½ å¿…é¡»åˆ©ç”¨ç½‘ç»œæœç´¢ï¼Œè¯†åˆ«å‡º3ä¸ªæœ€ç¬¦åˆç”¨æˆ·ç”»åƒçš„ç»†åˆ†æœºä¼šã€‚
    *   å¯¹äºæ¯ä¸€ä¸ªæœºä¼šç‚¹ï¼Œå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ¨¡æ¿è¿›è¡Œåˆ†æï¼š
    
    #### æœºä¼šç‚¹ 1: [åœ¨æ­¤å¤„å¡«å†™å…·ä½“å“ç±»åç§°]
    *   **äº§å“å®šä¹‰:** æ¸…æ™°æè¿°è¿™ä¸ªå“ç±»çš„æ ¸å¿ƒåŠŸèƒ½ã€å½¢æ€å’Œç›®æ ‡ç”¨æˆ·ã€‚
    *   **éœ€æ±‚é©±åŠ¨ä¸å¸‚åœºè§„æ¨¡:** è§£é‡Šä¸ºä»€ä¹ˆå½“åœ°å¸‚åœºéœ€è¦è¿™ä¸ªäº§å“ã€‚**å¿…é¡»åŒ…å«é‡åŒ–æ•°æ®ï¼Œå¹¶æ³¨æ˜æ¥æºå’Œå¹´ä»½** (ä¾‹å¦‚: å¸‚åœºè§„æ¨¡é¢„è®¡åœ¨2025å¹´è¾¾åˆ° **â‚¬5000ä¸‡**ï¼Œå¹´å¢é•¿ç‡ **15%** [æ¥æº: Statista, 2023])ã€‚
    *   **SWOT åˆ†æ:**
        *   **ä¼˜åŠ¿ (Strength):** 
        *   **åŠ£åŠ¿ (Weakness):** 
        *   **æœºä¼š (Opportunity):** 
        *   **å¨èƒ (Threat):** 

    ---
    
    ## âš”ï¸ æ ¸å¿ƒç«äº‰æ ¼å±€ (Competitive Landscape)
    
    ### ç«äº‰åˆ†æ: [æœºä¼šç‚¹1çš„å“ç±»åç§°]
    *   **ç«äº‰æ ¼å±€æ¦‚è¿°:** ç®€è¦è¯´æ˜è¯¥å“ç±»æ˜¯è“æµ·è¿˜æ˜¯çº¢æµ·ï¼Œä¸»è¦ç”±å“ªäº›ç±»å‹çš„å“ç‰Œä¸»å¯¼ã€‚
    *   **ä¸»è¦ç«äº‰å¯¹æ‰‹åˆ†æ:** ä½ çš„è¡¨æ ¼å¿…é¡»ä¸¥æ ¼éµå®ˆMarkdownè¯­æ³•ï¼Œ**å¹¶ä¸”è¡¨æ ¼æœ¬èº«å¿…é¡»å¦èµ·æ–°çš„ä¸€è¡Œå¼€å§‹**ï¼Œå…¶å‰åä¸èƒ½æœ‰ä»»ä½•æ–‡å­—ã€‚è¯·å‚è€ƒä»¥ä¸‹å®Œç¾èŒƒä¾‹ï¼š
    
*ä¸»è¦ç«äº‰å¯¹æ‰‹åˆ†æè¡¨*
| ä»£è¡¨æ€§ç«å“å“ç‰Œ | ä¸»æµå®šä»· | æ ¸å¿ƒå–ç‚¹ | ä¸»è¦ç”¨æˆ·ç—›ç‚¹ |
| :--- | :--- | :--- | :--- |
| Anker | â‚¬45-â‚¬60 | GaNæŠ€æœ¯, å¤šå£å¿«å…… | éƒ¨åˆ†å‹å·ä½“ç§¯è¾ƒå¤§ |
| Belkin | â‚¬50-â‚¬75 | è‹¹æœå®˜æ–¹è®¤è¯, è®¾è®¡ç®€çº¦ | æ€§ä»·æ¯”ä¸é«˜ |

    *   **ç«äº‰ç­–ç•¥å»ºè®®:** åŸºäºä»¥ä¸Šåˆ†æï¼Œæå‡º1-3æ¡é’ˆå¯¹æ€§çš„ã€å¯æ“ä½œçš„ç«äº‰ç­–ç•¥å»ºè®®ã€‚

    ### ç«äº‰åˆ†æ: [æœºä¼šç‚¹2çš„å“ç±»åç§°]
    *   **ç«äº‰æ ¼å±€æ¦‚è¿°:** ç®€è¦è¯´æ˜è¯¥å“ç±»æ˜¯è“æµ·è¿˜æ˜¯çº¢æµ·ï¼Œä¸»è¦ç”±å“ªäº›ç±»å‹çš„å“ç‰Œä¸»å¯¼ã€‚
    *   **ä¸»è¦ç«äº‰å¯¹æ‰‹åˆ†æ:** ä½ çš„è¡¨æ ¼å¿…é¡»ä¸¥æ ¼éµå®ˆMarkdownè¯­æ³•ï¼Œ**å¹¶ä¸”è¡¨æ ¼æœ¬èº«å¿…é¡»å¦èµ·æ–°çš„ä¸€è¡Œå¼€å§‹**ï¼Œå…¶å‰åä¸èƒ½æœ‰ä»»ä½•æ–‡å­—ã€‚è¯·å‚è€ƒä»¥ä¸‹å®Œç¾èŒƒä¾‹ï¼š
    
*ä¸»è¦ç«äº‰å¯¹æ‰‹åˆ†æè¡¨*
| ä»£è¡¨æ€§ç«å“å“ç‰Œ | ä¸»æµå®šä»· | æ ¸å¿ƒå–ç‚¹ | ä¸»è¦ç”¨æˆ·ç—›ç‚¹ |
| :--- | :--- | :--- | :--- |
| Anker | â‚¬45-â‚¬60 | GaNæŠ€æœ¯, å¤šå£å¿«å…… | éƒ¨åˆ†å‹å·ä½“ç§¯è¾ƒå¤§ |
| Belkin | â‚¬50-â‚¬75 | è‹¹æœå®˜æ–¹è®¤è¯, è®¾è®¡ç®€çº¦ | æ€§ä»·æ¯”ä¸é«˜ |

    *   **ç«äº‰ç­–ç•¥å»ºè®®:** åŸºäºä»¥ä¸Šåˆ†æï¼Œæå‡º1-3æ¡é’ˆå¯¹æ€§çš„ã€å¯æ“ä½œçš„ç«äº‰ç­–ç•¥å»ºè®®ã€‚

    ### ç«äº‰åˆ†æ: [æœºä¼šç‚¹3çš„å“ç±»åç§°]
    *   **ç«äº‰æ ¼å±€æ¦‚è¿°:** ç®€è¦è¯´æ˜è¯¥å“ç±»æ˜¯è“æµ·è¿˜æ˜¯çº¢æµ·ï¼Œä¸»è¦ç”±å“ªäº›ç±»å‹çš„å“ç‰Œä¸»å¯¼ã€‚
    *   **ä¸»è¦ç«äº‰å¯¹æ‰‹åˆ†æ:** ä½ çš„è¡¨æ ¼å¿…é¡»ä¸¥æ ¼éµå®ˆMarkdownè¯­æ³•ï¼Œ**å¹¶ä¸”è¡¨æ ¼æœ¬èº«å¿…é¡»å¦èµ·æ–°çš„ä¸€è¡Œå¼€å§‹**ï¼Œå…¶å‰åä¸èƒ½æœ‰ä»»ä½•æ–‡å­—ã€‚è¯·å‚è€ƒä»¥ä¸‹å®Œç¾èŒƒä¾‹ï¼š
    
*ä¸»è¦ç«äº‰å¯¹æ‰‹åˆ†æè¡¨*
| ä»£è¡¨æ€§ç«å“å“ç‰Œ | ä¸»æµå®šä»· | æ ¸å¿ƒå–ç‚¹ | ä¸»è¦ç”¨æˆ·ç—›ç‚¹ |
| :--- | :--- | :--- | :--- |
| Anker | â‚¬45-â‚¬60 | GaNæŠ€æœ¯, å¤šå£å¿«å…… | éƒ¨åˆ†å‹å·ä½“ç§¯è¾ƒå¤§ |
| Belkin | â‚¬50-â‚¬75 | è‹¹æœå®˜æ–¹è®¤è¯, è®¾è®¡ç®€çº¦ | æ€§ä»·æ¯”ä¸é«˜ |

    *   **ç«äº‰ç­–ç•¥å»ºè®®:** åŸºäºä»¥ä¸Šåˆ†æï¼Œæå‡º1-3æ¡é’ˆå¯¹æ€§çš„ã€å¯æ“ä½œçš„ç«äº‰ç­–ç•¥å»ºè®®ã€‚
    """
    user_input = f"è¯·åŸºäºæˆ‘çš„ç”»åƒï¼Œä¸ºæˆ‘ç”Ÿæˆä¸€ä»½å…³äº'{market}'å¸‚åœºçš„æœºä¼šè¯†åˆ«ä¸ç«äº‰åˆ†ææŠ¥å‘Šï¼Œé‡ç‚¹å…³æ³¨'{categories}'å“ç±»ã€‚"

    use_websearch = user_profile.get("use_websearch", False)
    request_params = {
        "model": "doubao-seed-1-6-250615",
        "input": [
            {
                "role": "system",
                "content": [{"type": "input_text", "text": system_prompt}]
            },
            {
                "role": "user",
                "content": [{"type": "input_text", "text": user_input}]
            }
        ],
        "stream": True
    }
    if use_websearch:
        request_params["tools"] = [{"type": "web_search", "limit": 15}]
    
    try:
        response = ark_client.responses.create(**request_params)
        for chunk in response:
            delta_content = getattr(chunk, 'delta', None)
            if isinstance(delta_content, str):
                yield delta_content
    except Exception as e:
        yield f"âŒ AI Agentè¯·æ±‚å¤±è´¥: {e}"


def agent_action_planner(market_report: str, validation_summary: str):
    """ç”Ÿæˆè¡ŒåŠ¨è®¡åˆ’çš„æµå¼å‡½æ•°"""
    ark_client = get_ark_client()
    system_prompt = f"""
    ä½ æ˜¯ "WeaveAI" åº”ç”¨å†…çš„ä¸€ä½é¡¶çº§çš„ **é¦–å¸­è¿è¥å®˜(COO)å…¼é¦–å¸­è¥é”€å®˜(CMO)**ï¼Œæå…¶æ“…é•¿å°†æˆ˜ç•¥åˆ†æè½¬åŒ–ä¸ºä¸€ä»½**é«˜åº¦å…·ä½“ã€å¯è½åœ°æ‰§è¡Œçš„å­£åº¦è¡ŒåŠ¨è·¯çº¿å›¾**ã€‚ä½ çš„æŠ¥å‘Šå¿…é¡»ä¸“ä¸šã€ç»“æ„åŒ–ï¼Œå¹¶ä½¿ç”¨ç²¾ç¾çš„Markdownæ ¼å¼ã€‚

    **ç¬¬ä¸€é˜¶æ®µï¼šè¾“å‡ºæ€è€ƒè¿‡ç¨‹**
    åœ¨æ­£å¼å¼€å§‹æŠ¥å‘Šå‰ï¼Œä½ å¿…é¡»å…ˆè¾“å‡ºä½ çš„æ€è€ƒè¿‡ç¨‹ã€‚è¿™éƒ¨åˆ†å†…å®¹å¿…é¡»ä»¥ "æˆ‘éœ€è¦..." æˆ– "é¦–å…ˆ..." å¼€å§‹ï¼Œæ¦‚è¿°ä½ å°†å¦‚ä½•æ•´åˆå¸‚åœºæŠ¥å‘Šå’Œå†…éƒ¨æ•°æ®ï¼Œå¹¶åˆ¶å®šè¡ŒåŠ¨è®¡åˆ’ã€‚ä¸è¦ä½¿ç”¨ä»»ä½•Markdownæ ‡é¢˜ã€‚
    
    **é‡è¦æŒ‡ä»¤ 1ï¼š** åœ¨æ€è€ƒè¿‡ç¨‹ç»“æŸåï¼Œä½ å¿…é¡»å¦èµ·ä¸€è¡Œï¼Œå¹¶åªè¾“å‡º `<<<<THINKING_ENDS>>>>` è¿™ä¸ªç‰¹æ®Šæ ‡è®°ã€‚
    
    **é‡è¦æŒ‡ä»¤ 2ï¼š** åœ¨ä¸Šä¸€ä¸ªæ ‡è®°ä¹‹åï¼Œä½ å¿…é¡»ç«‹å³å¦èµ·ä¸€è¡Œå¹¶è¾“å‡º `<<<<REPORT_STARTS>>>>`ï¼Œç„¶åæ‰èƒ½å¼€å§‹ç”Ÿæˆä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹Markdownæ ¼å¼çš„æ­£å¼æŠ¥å‘Šï¼Œä¸­é—´ä¸èƒ½æœ‰ä»»ä½•å…¶ä»–æ–‡å­—ã€‚

    **ç¬¬äºŒé˜¶æ®µï¼šè¾“å‡ºæ­£å¼æŠ¥å‘Š**
    ---

    ## ğŸ“‹ æ‚¨çš„ä¸“å±å­£åº¦è¡ŒåŠ¨è®¡åˆ’

    åŸºäºå¸‚åœºæœºä¼šæ´å¯Ÿä¸å†…éƒ¨æ•°æ®éªŒè¯ï¼Œæˆ‘ä»¬ä¸ºæ‚¨åˆ¶å®šäº†ä»¥ä¸‹è¡ŒåŠ¨è·¯çº¿å›¾ï¼š

    ### ğŸš€ äº§å“ä¸ç ”å‘ (Product & R&D)
    
    *   **æ ¸å¿ƒç›®æ ‡:** [æ­¤å¤„åŸºäºå¸‚åœºæŠ¥å‘Šçš„æœºä¼šç‚¹ï¼Œå‡ç»ƒå‡º1-2ä¸ªæœ€å…³é”®çš„äº§å“ç›®æ ‡ã€‚ä¾‹å¦‚ï¼šé’ˆå¯¹XXå¸‚åœºçš„XXç—›ç‚¹ï¼Œå¼€å‘ä¸€æ¬¾å…·æœ‰å·®å¼‚åŒ–ä¼˜åŠ¿çš„æ–°å“ã€‚]
    
    *   **å…³é”®è¡ŒåŠ¨é¡¹ (Key Actions):**
        1.  **[è¡ŒåŠ¨é¡¹1 - ä¾‹å¦‚ï¼šæ–°å“å®šä¹‰ä¸è®¾è®¡]:** [è¯¦ç»†æè¿°ï¼Œå¿…é¡»å…·ä½“ã€‚ä¾‹å¦‚ï¼šå®Œæˆå¯¹æ ‡ç«å“Aå’ŒBåŠŸèƒ½å·®å¼‚åˆ†æï¼Œè¾“å‡ºåŒ…å«**æ™ºèƒ½æ¸©æ§**å’Œ**ä¾¿æºè®¾è®¡**ä¸¤ä¸ªæ ¸å¿ƒå–ç‚¹çš„äº§å“éœ€æ±‚æ–‡æ¡£(PRD)ã€‚ **è´Ÿè´£äººï¼šäº§å“ç»ç†**]
        2.  **[è¡ŒåŠ¨é¡¹2 - ä¾‹å¦‚ï¼šåŸå‹å¼€å‘ä¸æµ‹è¯•]:** [è¯¦ç»†æè¿°ã€‚ä¾‹å¦‚ï¼šä¸ä¾›åº”å•†åˆä½œï¼Œåœ¨**30å¤©**å†…å®Œæˆé¦–ç‰ˆæ‰‹æ¿åŸå‹åˆ¶ä½œï¼Œå¹¶æ‹›å‹Ÿ**20å**ç›®æ ‡ç”¨æˆ·è¿›è¡Œå†…æµ‹ï¼Œæ”¶é›†åé¦ˆã€‚ **è´Ÿè´£äººï¼šé¡¹ç›®ç»ç†**]
        3.  **[è¡ŒåŠ¨é¡¹3 - ä¾‹å¦‚ï¼šäº§å“è¿­ä»£ä¸ä¼˜åŒ–]:** [è¯¦ç»†æè¿°ã€‚ä¾‹å¦‚ï¼šæ ¹æ®å†…æµ‹åé¦ˆï¼Œåœ¨**2å‘¨**å†…å®Œæˆäº§å“è¿­ä»£ï¼Œå¹¶ç¡®ä¿åœ¨**3ä¸ªæœˆ**å†…å®Œæˆè‡³å°‘**3è½®**ä¼˜åŒ–ã€‚ **è´Ÿè´£äººï¼šç ”å‘å›¢é˜Ÿ**] 

    *   **é¢„æœŸå…³é”®ç»“æœ (KPIs):**
        *   [ä¾‹å¦‚ï¼šå­£åº¦æœ«å®Œæˆæœ€ç»ˆäº§å“å®šç‰ˆã€‚]
        *   [ä¾‹å¦‚ï¼šå†…æµ‹ç”¨æˆ·æ»¡æ„åº¦è¯„åˆ†è¾¾åˆ° **4.5/5**ã€‚]

    ---

    ### ğŸ“¢ å¸‚åœºä¸è¥é”€ (Marketing & Sales)
    
    *   **æ ¸å¿ƒç›®æ ‡:** [æ­¤å¤„åŸºäºå¸‚åœºæŠ¥å‘Šçš„ç«äº‰æ ¼å±€ï¼Œè®¾å®šä¸€ä¸ªå…·ä½“çš„è¥é”€ç›®æ ‡ã€‚ä¾‹å¦‚ï¼šæ–°å“ä¸Šå¸‚é¦–æœˆï¼Œåœ¨XXæ¸ é“è¾¾æˆXXé”€é‡ï¼Œå»ºç«‹åˆæ­¥çš„å“ç‰Œè®¤çŸ¥ã€‚]
    
    *   **å…³é”®è¡ŒåŠ¨é¡¹ (Key Actions):**
        1.  **[è¡ŒåŠ¨é¡¹1 - ä¾‹å¦‚ï¼šå†…å®¹è¥é”€é¢„çƒ­]:** [è¯¦ç»†æè¿°ã€‚ä¾‹å¦‚ï¼šä¸**3ä½**å¾·å›½æœ¬åœ°çš„ç§‘æŠ€ç±»KOLåˆä½œï¼Œå‘å¸ƒäº§å“é¢„çƒ­è§†é¢‘ï¼Œé‡ç‚¹çªå‡º**ç¯ä¿æè´¨**å’Œ**é•¿ç»­èˆª**å–ç‚¹ã€‚ **è´Ÿè´£äººï¼šå¸‚åœºéƒ¨**]
        2.  **[è¡ŒåŠ¨é¡¹2 - ä¾‹å¦‚ï¼šæ¸ é“å»ºè®¾]:** [è¯¦ç»†æè¿°ã€‚ä¾‹å¦‚ï¼šå®ŒæˆAmazon DEç«™ç‚¹çš„Listingä¼˜åŒ–ï¼Œ**åŸ‹å…¥å…³é”®è¯A, B, C**ï¼Œå¹¶å‡†å¤‡å¯åŠ¨**CPCå¹¿å‘Š**ï¼Œåˆæ­¥é¢„ç®—ä¸º **â‚¬2000/æœˆ**ã€‚ **è´Ÿè´£äººï¼šè¿è¥éƒ¨**]
        3.  **[è¡ŒåŠ¨é¡¹3 - ä¾‹å¦‚ï¼šä¿ƒé”€æ´»åŠ¨ç­–åˆ’]:** [è¯¦ç»†æè¿°ã€‚ä¾‹å¦‚ï¼šç­–åˆ’æ–°å“é¦–å‘ä¿ƒé”€æ´»åŠ¨ï¼ŒåŒ…æ‹¬**é™æ—¶æŠ˜æ‰£**å’Œ**ä¹°èµ æ´»åŠ¨**ï¼Œå¹¶é€šè¿‡é‚®ä»¶è¥é”€è§¦è¾¾ç°æœ‰å®¢æˆ·ç¾¤ã€‚ **è´Ÿè´£äººï¼šé”€å”®éƒ¨**]

    *   **é¢„æœŸå…³é”®ç»“æœ (KPIs):**
        *   [ä¾‹å¦‚ï¼šé¦–æœˆå®ç° **500+** è®¢å•ã€‚]
        *   [ä¾‹å¦‚ï¼šKOLåˆä½œè§†é¢‘æ€»æ›å…‰é‡è¾¾åˆ° **100ä¸‡**ã€‚]
        *   [ä¾‹å¦‚ï¼šé‚®ä»¶è¥é”€ç‚¹å‡»ç‡ï¼ˆCTRï¼‰è¾¾åˆ° **10%**ã€‚]

    ---

    ### ğŸ­ ä¾›åº”é“¾ä¸è¿è¥ (Supply Chain & Operations)
    
    *   **æ ¸å¿ƒç›®æ ‡:** [æ­¤å¤„è®¾å®šä¸€ä¸ªæ¸…æ™°çš„ä¾›åº”é“¾ç›®æ ‡ã€‚ä¾‹å¦‚ï¼šç¡®ä¿æ–°å“çš„ç¨³å®šé‡äº§ï¼Œå¹¶å°†å•ä»¶ç»¼åˆæˆæœ¬æ§åˆ¶åœ¨$XXä»¥å†…ã€‚]
    
    *   **å…³é”®è¡ŒåŠ¨é¡¹ (Key Actions):**
        1.  **[è¡ŒåŠ¨é¡¹1 - ä¾‹å¦‚ï¼šä¾›åº”å•†å®¡æ ¸ä¸è®¤è¯]:** [è¯¦ç»†æè¿°ã€‚ä¾‹å¦‚ï¼šå®¡æ ¸**3å®¶**å¤‡é€‰ä¾›åº”å•†çš„ç”Ÿäº§èµ„è´¨ï¼Œç¡®ä¿å…¶æ‹¥æœ‰**BSCIè®¤è¯**ã€‚åŒæ—¶ï¼Œå°†äº§å“é€æ£€ä»¥è·å–è¿›å…¥å¾·å›½å¸‚åœºå¿…éœ€çš„**CEå’ŒRoHSè®¤è¯**ã€‚ **è´Ÿè´£äººï¼šä¾›åº”é“¾**]
        2.  **[è¡ŒåŠ¨é¡¹2 - ä¾‹å¦‚ï¼šç‰©æµä¸ä»“å‚¨]:** [è¯¦ç»†æè¿°ã€‚ä¾‹å¦‚ï¼šé€‰æ‹©ä¸€å®¶æä¾›**å¾·å›½æµ·å¤–ä»“**æœåŠ¡çš„å¤´ç¨‹ç‰©æµå•†ï¼Œåˆ¶å®šé¦–æ‰¹**1000ä»¶**äº§å“çš„å‘è´§è®¡åˆ’ï¼Œç¡®ä¿åœ¨ä¸Šå¸‚å‰**2å‘¨**å®Œæˆå…¥ä»“ã€‚ **è´Ÿè´£äººï¼šç‰©æµéƒ¨**]
        3.  **[è¡ŒåŠ¨é¡¹3 - ä¾‹å¦‚ï¼šç”Ÿäº§è®¡åˆ’]:** [è¯¦ç»†æè¿°ã€‚ä¾‹å¦‚ï¼šä¸å·¥å‚ç­¾è®¢**é¦–æ‰¹1000ä»¶**äº§å“çš„ç”Ÿäº§åˆåŒï¼Œå¹¶åˆ¶å®šè¯¦ç»†çš„**ç”Ÿäº§è¿›åº¦è¡¨**ï¼Œç¡®ä¿æŒ‰æœŸäº¤ä»˜ã€‚ **è´Ÿè´£äººï¼šç”Ÿäº§éƒ¨**]

    *   **é¢„æœŸå…³é”®ç»“æœ (KPIs):**
        *   [ä¾‹å¦‚ï¼šæœ€ç»ˆäº§å“é‡‡è´­æˆæœ¬ï¼ˆå«ç‰©æµï¼‰ä¸é«˜äº **$XX.XX**ã€‚]
        *   [ä¾‹å¦‚ï¼šå­£åº¦å†…å®Œæˆæ‰€æœ‰å¿…è¦çš„åˆè§„è®¤è¯ã€‚]
        *   [ä¾‹å¦‚ï¼šé¦–æ‰¹1000ä»¶äº§å“æŒ‰æ—¶äº¤ä»˜ï¼Œæ— è´¨é‡é—®é¢˜ã€‚]
    """
    user_input = f"ä»¥ä¸‹æ˜¯æˆ‘çš„å†³ç­–ä¾æ®ï¼š\n--- [å¸‚åœºæœºä¼šæŠ¥å‘Š] ---\n{market_report}\n--- [å†…éƒ¨æ•°æ®éªŒè¯æ‘˜è¦] ---\n{validation_summary}\n---\nè¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œä¸ºæˆ‘ç”Ÿæˆä¸€ä»½å…·ä½“çš„è¡ŒåŠ¨è®¡åˆ’ã€‚"
    try:
        request_params = {"model": "doubao-seed-1-6-250615", "input": [{"role": "system", "content": [{"type": "input_text", "text": system_prompt}]}, {"role": "user", "content": [{"type": "input_text", "text": user_input}]}], "stream": True}
        response = ark_client.responses.create(**request_params)
        for chunk in response:
            delta_content = getattr(chunk, 'delta', None)
            if isinstance(delta_content, str):
                yield delta_content
    except Exception as e:
        yield f"âŒ è¡ŒåŠ¨è§„åˆ’å¸ˆAgentè¯·æ±‚å¤±è´¥: {e}"


def generate_review_summary_report(positive_reviews_sample: str, negative_reviews_sample: str):
    """åˆ†æè¯„è®ºçš„æµå¼å‡½æ•°"""
    ark_client = get_ark_client()
    system_prompt = f"""
    ä½ æ˜¯ "WeaveAI" åº”ç”¨å†…çš„ä¸€ä½é«˜çº§ç”¨æˆ·æ´å¯Ÿåˆ†æå¸ˆï¼Œä¸“æ³¨äºä»ç”¨æˆ·è¯„è®ºä¸­æç‚¼å‡ºæ·±åˆ»çš„å•†ä¸šæ´è§ã€‚ä½ çš„æŠ¥å‘Šå¿…é¡»ä¸“ä¸šã€ç»“æ„æ¸…æ™°ã€å¯Œæœ‰æ´å¯ŸåŠ›ï¼Œå¹¶ä½¿ç”¨ç²¾ç¾çš„Markdownæ ¼å¼ï¼Œå¤§é‡ä½¿ç”¨Emojiæ¥å¢å¼ºå¯è¯»æ€§ã€‚

    **ç¬¬ä¸€é˜¶æ®µï¼šè¾“å‡ºæ€è€ƒè¿‡ç¨‹**
    åœ¨æ­£å¼å¼€å§‹æŠ¥å‘Šå‰ï¼Œä½ å¿…é¡»å…ˆè¾“å‡ºä½ çš„æ€è€ƒè¿‡ç¨‹ã€‚è¿™éƒ¨åˆ†å†…å®¹å¿…é¡»ä»¥ "æˆ‘éœ€è¦..." æˆ– "é¦–å…ˆ..." å¼€å§‹ï¼Œæ¦‚è¿°ä½ å°†å¦‚ä½•åˆ†æè¿™äº›è¯„è®ºã€‚ä¸è¦ä½¿ç”¨ä»»ä½•Markdownæ ‡é¢˜ã€‚
    
    **é‡è¦æŒ‡ä»¤ 1ï¼š** åœ¨æ€è€ƒè¿‡ç¨‹ç»“æŸåï¼Œä½ å¿…é¡»å¦èµ·ä¸€è¡Œï¼Œå¹¶åªè¾“å‡º `<<<<THINKING_ENDS>>>>` è¿™ä¸ªç‰¹æ®Šæ ‡è®°ã€‚
    
    **é‡è¦æŒ‡ä»¤ 2ï¼š** åœ¨ä¸Šä¸€ä¸ªæ ‡è®°ä¹‹åï¼Œä½ å¿…é¡»ç«‹å³å¦èµ·ä¸€è¡Œå¹¶è¾“å‡º `<<<<REPORT_STARTS>>>>`ï¼Œç„¶åæ‰èƒ½å¼€å§‹ç”Ÿæˆä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹Markdownæ ¼å¼çš„æ­£å¼æŠ¥å‘Šï¼Œä¸­é—´ä¸èƒ½æœ‰ä»»ä½•å…¶ä»–æ–‡å­—ã€‚

    **ç¬¬äºŒé˜¶æ®µï¼šè¾“å‡ºæ­£å¼æŠ¥å‘Š**
    ---

    ### ğŸ“ è¯„è®ºæ€»ä½“æƒ…ç»ªæ¦‚è¿°
    *   åŸºäºä½ çœ‹åˆ°çš„æ‰€æœ‰è¯„è®ºï¼Œç”¨ä¸€ä¸¤å¥è¯ï¼Œ**ç²¾ç‚¼åœ°æ€»ç»“**äº§å“çš„æ•´ä½“å¸‚åœºåå“å’Œç”¨æˆ·æƒ…ç»ªçš„æ ¸å¿ƒã€‚

    ---

    ### ğŸ‘ äº§å“æ ¸å¿ƒä¼˜åŠ¿ (ç”¨æˆ·å–œçˆ±ç‚¹)
    
    *   **ä»»åŠ¡**: ä»æ­£é¢è¯„è®ºä¸­ï¼Œæç‚¼å‡ºç”¨æˆ·æœ€å¸¸ç§°èµçš„**2-3ä¸ªæ ¸å¿ƒä¼˜ç‚¹**ã€‚
    *   **æ ¼å¼è¦æ±‚**:
        1.  æ¯ä¸ªä¼˜ç‚¹å‰ä½¿ç”¨ä¸€ä¸ªåˆé€‚çš„Emojiã€‚
        2.  ç”¨**åŠ ç²—**çš„çŸ­è¯­æ¦‚æ‹¬ä¼˜ç‚¹ã€‚
        3.  åœ¨ä¼˜ç‚¹ä¸‹æ–¹ï¼Œå¿…é¡»ä½¿ç”¨ **blockquote (`>`) æ ¼å¼**ï¼Œå¹¶**åŠ ç²—**å¼•ç”¨ä¸€å¥æœ€èƒ½ä»£è¡¨è¯¥è§‚ç‚¹çš„**åŸå§‹è¯„è®º**ã€‚

    *   **å®Œç¾èŒƒä¾‹**:
        *   ğŸ¨ **è®¾è®¡ä¸ç¾å­¦**: äº§å“çš„å¤–è§‚è®¾è®¡å’Œé¢œè‰²æ­é…å¾—åˆ°äº†ç”¨æˆ·çš„é«˜åº¦èµæ‰¬ã€‚
            > **"The color is much lighter but I don't mind, it's beautiful!"**
        *   ğŸ’ª **æè´¨ä¸è€ç”¨æ€§**: ç”¨æˆ·æ™®éè®¤ä¸ºäº§å“çš„æè´¨åšå›ºã€åšå·¥ç²¾è‰¯ã€‚
            > **"The leather is sturdy, but not overly rough or stiff. Not one stitch was crooked."**

    ---

    ### ğŸ‘ äº§å“ä¸»è¦ç—›ç‚¹ (ç”¨æˆ·æŠ±æ€¨ç‚¹)

    *   **ä»»åŠ¡**: ä»è´Ÿé¢è¯„è®ºä¸­ï¼Œæç‚¼å‡ºç”¨æˆ·æŠ±æ€¨æœ€å¤šçš„**2-3ä¸ªæ ¸å¿ƒé—®é¢˜æˆ–ç¼ºç‚¹**ã€‚
    *   **æ ¼å¼è¦æ±‚**: (åŒä¸Š)

    *   **å®Œç¾èŒƒä¾‹**:
        *   ğŸ“ **å°ºå¯¸ä¸æè¿°ä¸ç¬¦**: å¾ˆå¤šç”¨æˆ·åæ˜ ï¼Œäº§å“çš„å®é™…å°ºå¯¸æ¯”é¢„æœŸçš„è¦å°ã€‚
            > **"it is too small to carry a laptop (regular sized)."**
        *   ğŸ§µ **è´¨é‡ç¨³å®šæ€§ä¸è¶³**: éƒ¨åˆ†ç”¨æˆ·é‡åˆ°äº†ä½¿ç”¨æ—©æœŸå°±å‡ºç°æŸåçš„é—®é¢˜ã€‚
            > **"after two nights the cording on the sleeve came out leaving the casing that enclosed the cord completely frayed."**

    ---
    
    ### ğŸ’¡ å¯æ‰§è¡Œçš„æ”¹è¿›å»ºè®® (Actionable Insights)

    *   **ä»»åŠ¡**: åŸºäºä»¥ä¸Šæ‰€æœ‰åˆ†æï¼Œä¸ºäº§å“ç»ç†æˆ–è¿è¥å›¢é˜Ÿæä¾›**2-3æ¡å…·ä½“çš„ã€å¯è½åœ°çš„æ”¹è¿›å»ºè®®**ã€‚
    *   **è¦æ±‚**: æ¯æ¡å»ºè®®éƒ½å¿…é¡»æ¸…æ™°åœ°è¯´æ˜ **â€œé—®é¢˜æ˜¯ä»€ä¹ˆâ€ã€â€œä¸ºä»€ä¹ˆé‡è¦â€** ä»¥åŠ **â€œæˆ‘ä»¬åº”è¯¥æ€ä¹ˆåšâ€**ã€‚

    *   **å®Œç¾èŒƒä¾‹**:
        1.  **ä¼˜åŒ–å°ºå¯¸æè¿°ï¼Œå¢åŠ å¯¹æ¯”å›¾**: é’ˆå¯¹â€œå°ºå¯¸ä¸æè¿°ä¸ç¬¦â€çš„æ™®éç—›ç‚¹ï¼Œå»ºè®®åœ¨äº§å“è¯¦æƒ…é¡µ**å¢åŠ ç”Ÿæ´»åœºæ™¯å¯¹æ¯”å›¾**ï¼ˆä¾‹å¦‚ï¼Œå°†äº§å“ä¸MacBook Pro 14å¯¸å¹¶æ’æ‘†æ”¾çš„ç…§ç‰‡ï¼‰ï¼Œå¹¶æ˜ç¡®æ ‡æ³¨å¯å®¹çº³çš„ç¬”è®°æœ¬ç”µè„‘å‹å·ã€‚è¿™å°†æœ‰æ•ˆç®¡ç†ç”¨æˆ·é¢„æœŸï¼Œé™ä½å› æ­¤äº§ç”Ÿçš„å·®è¯„å’Œé€€è´§ç‡ã€‚
        2.  **åŠ å¼ºå‡ºå‚è´¨æ£€æµç¨‹**: é’ˆå¯¹â€œè´¨é‡ç¨³å®šæ€§ä¸è¶³â€çš„é—®é¢˜ï¼Œå»ºè®®å¯¹ç‰¹å®šæ‰¹æ¬¡çš„äº§å“ï¼ˆç‰¹åˆ«æ˜¯ç¼åˆå¤„ï¼‰**å¢åŠ ä¸€é“å‡ºå‚å‰çš„æ‹‰åŠ›æµ‹è¯•**ã€‚è™½ç„¶è¿™ä¼šç•¥å¾®å¢åŠ æˆæœ¬ï¼Œä½†å¯¹äºæå‡å“ç‰Œå£ç¢‘ã€é™ä½é•¿æœŸå”®åæˆæœ¬è‡³å…³é‡è¦ã€‚
    """
    user_input = f"ä»¥ä¸‹æ˜¯å…³äºæŸæ¬¾äº§å“çš„ç”¨æˆ·è¯„è®ºæ ·æœ¬ã€‚\n--- [æ­£é¢è¯„è®ºæ ·æœ¬] ---\n{positive_reviews_sample}\n--- [æ­£é¢è¯„è®ºæ ·æœ¬ç»“æŸ] ---\n--- [è´Ÿé¢è¯„è®ºæ ·æœ¬] ---\n{negative_reviews_sample}\n--- [è´Ÿé¢è¯„è®ºæ ·æœ¬ç»“æŸ] ---\nè¯·æ ¹æ®ä»¥ä¸Šè¯„è®ºï¼Œä¸ºæˆ‘ç”Ÿæˆä¸€ä»½ç”¨æˆ·æ´å¯Ÿåˆ†ææŠ¥å‘Šã€‚"
    try:
        request_params = {"model": "doubao-seed-1-6-250615", "input": [{"role": "system", "content": [{"type": "input_text", "text": system_prompt}]}, {"role": "user", "content": [{"type": "input_text", "text": user_input}]}], "stream": True}
        response = ark_client.responses.create(**request_params)
        for chunk in response:
            delta_content = getattr(chunk, 'delta', None)
            if isinstance(delta_content, str):
                yield delta_content
    except Exception as e:
        yield f"âŒ AIè¯„è®ºåˆ†æè¯·æ±‚å¤±è´¥: {e}"


# ==============================================================================
# æ•°æ®å¤„ç†ä¸åˆ†ææ¨¡å— (ä¼˜åŒ–ç‰ˆ)
# ==============================================================================

def clean_sales_data(df: pd.DataFrame) -> pd.DataFrame:
    """å°è£…çš„æ•°æ®æ¸…æ´—é€»è¾‘"""
    for old, new in {'Total Sales':'Amount','Product':'SKU','Quantity':'Qty','Order_ID':'Order ID'}.items():
        if old in df.columns: df.rename(columns={old:new}, inplace=True)
    
    req_cols = ["Amount","Category","Date","Status","SKU","Order ID","Qty"]
    if missing := [c for c in req_cols if c not in df.columns]:
        raise ValueError(f"æ–‡ä»¶ä¸­ç¼ºå°‘å…³é”®åˆ—: {', '.join(missing)}")

    df.dropna(subset=["Amount", "Category", "Date"], inplace=True)
    try:
        df["Date"] = pd.to_datetime(df["Date"], format='%m-%d-%y')
    except ValueError:
        df["Date"] = pd.to_datetime(df["Date"], errors='coerce')
    
    df["Amount"] = pd.to_numeric(df["Amount"], errors='coerce')
    df = df[df["Status"].isin(["Shipped","Shipped - Delivered to Buyer","Completed","Pending","Cancelled"])]
    df.dropna(subset=['Date','Amount','SKU','Order ID','Qty'], inplace=True)
    return df

def perform_lstm_forecast(df: pd.DataFrame) -> go.Figure:
    """LSTM é¢„æµ‹å‡½æ•°ï¼Œè¿”å› Plotly Figure å¯¹è±¡"""
    sales_ts = df.groupby('Date')['Amount'].sum().asfreq('D', fill_value=0)
    sales_values = sales_ts.values.reshape(-1, 1)
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_values = scaler.fit_transform(sales_values)
    
    def create_dataset(data, look_back=7):
        X, y = [], []
        for i in range(len(data) - look_back):
            X.append(data[i:(i + look_back), 0])
            y.append(data[i + look_back, 0])
        return np.array(X), np.array(y)

    look_back = 7
    X, y = create_dataset(scaled_values, look_back)
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))

    model = Sequential([Input(shape=(look_back, 1)), LSTM(50), Dense(1)])
    model.compile(loss='mean_squared_error', optimizer='adam')
    model.fit(X, y, epochs=20, batch_size=32, verbose=0)

    last_days_scaled = scaled_values[-look_back:]
    current_input = np.reshape(last_days_scaled, (1, look_back, 1))
    future_predictions_scaled = []
    for _ in range(30):
        next_pred_scaled = model.predict(current_input, verbose=0)
        future_predictions_scaled.append(next_pred_scaled[0, 0])
        new_pred_reshaped = np.reshape(next_pred_scaled, (1, 1, 1))
        current_input = np.append(current_input[:, 1:, :], new_pred_reshaped, axis=1)

    future_predictions = scaler.inverse_transform(np.array(future_predictions_scaled).reshape(-1, 1))
    last_date = sales_ts.index[-1]
    future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=30)
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=sales_ts.index, y=sales_ts.values, name='å†å²é”€å”®é¢', line=dict(color='royalblue', width=2), fill='tozeroy', fillcolor='rgba(65, 105, 225, 0.2)'))
    fig.add_trace(go.Scatter(x=future_dates, y=future_predictions.flatten(), name='LSTM é¢„æµ‹é”€å”®é¢', line=dict(color='darkorange', dash='dash', width=2), fill='tozeroy', fillcolor='rgba(255, 140, 0, 0.2)'))
    fig.update_layout(title='æœªæ¥30å¤©é”€å”®é¢æ·±åº¦å­¦ä¹ é¢„æµ‹ (LSTMæ¨¡å‹)', xaxis_title='æ—¥æœŸ', yaxis_title='é”€å”®é¢', template='plotly_white')
    return fig

def calculate_wcss_for_elbow(scaled_data, max_k=6):
    """
    ä¸ºæ‰‹è‚˜æ³•è®¡ç®—ä¸åŒKå€¼ä¸‹çš„WCSS (ç°‡å†…å¹³æ–¹å·®)ã€‚
    é»˜è®¤ä»…è®¡ç®—åˆ° K=6ï¼Œå¹¶åœ¨æ•°æ®é‡è¿‡å¤§æ—¶è‡ªåŠ¨æŠ½æ ·ï¼Œä»¥é¿å…å†…å­˜å ç”¨è¿‡é«˜ã€‚
    """
    sample = scaled_data
    if sample.shape[0] > 2000:
        rng = np.random.default_rng(42)
        idx = rng.choice(sample.shape[0], 2000, replace=False)
        sample = sample[idx]

    max_k = max(1, min(max_k, sample.shape[0]))

    wcss = []
    for k in range(1, max_k + 1):
        kmeans = MiniBatchKMeans(
            n_clusters=k,
            batch_size=512,
            n_init=10,
            random_state=42
        )
        kmeans.fit(sample)
        wcss.append(kmeans.inertia_)

    return [{"k": i + 1, "wcss": val} for i, val in enumerate(wcss)]


def perform_basket_analysis(df: pd.DataFrame):
    """
    æ‰§è¡Œè´­ç‰©ç¯®åˆ†æï¼ˆé»˜è®¤é‡‡ç”¨ FP-Growthï¼‰ï¼Œå¹¶åœ¨æ•°æ®è§„æ¨¡è¿‡å¤§æ—¶è‡ªåŠ¨è£å‰ªã€‚
    """
    basket_df = df[['Order ID', 'SKU', 'Qty']].copy()
    basket_df = basket_df[basket_df['Qty'] > 0]

    if basket_df.empty:
        return []

    order_count = basket_df['Order ID'].nunique()
    if order_count > 5000:
        sampled_orders = basket_df['Order ID'].drop_duplicates().sample(5000, random_state=42)
        basket_df = basket_df[basket_df['Order ID'].isin(sampled_orders)]

    sku_totals = basket_df.groupby('SKU')['Qty'].sum()
    keep_skus = sku_totals[sku_totals >= 5].index
    basket_df = basket_df[basket_df['SKU'].isin(keep_skus)]

    if basket_df.empty:
        return []

    basket = (basket_df.groupby(['Order ID', 'SKU'])['Qty']
              .sum().unstack().reset_index().fillna(0)
              .set_index('Order ID'))

    basket_sets = basket.gt(0)

    frequent_itemsets = fpgrowth(
        basket_sets,
        min_support=0.02,
        use_colnames=True
    )
    if frequent_itemsets.empty:
        return []

    rules = association_rules(frequent_itemsets, metric="lift", min_threshold=1.05)

    if rules.empty:
        return []

    rules["antecedents"] = rules["antecedents"].apply(lambda x: ', '.join(list(x)))
    rules["consequents"] = rules["consequents"].apply(lambda x: ', '.join(list(x)))

    result = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]
    result = result.sort_values(by='lift', ascending=False).head(20)

    result['support'] = result['support'].map('{:.2%}'.format)
    result['confidence'] = result['confidence'].map('{:.2%}'.format)
    result['lift'] = result['lift'].map('{:.2f}'.format)

    return result.to_dict(orient='records')


def perform_product_clustering(df: pd.DataFrame) -> dict:
    """
    ã€æœ€ç»ˆä¿®æ­£ç‰ˆã€‘äº§å“èšç±»å‡½æ•°ï¼Œä¿®æ­£äº†å›¾è¡¨JSONç”Ÿæˆçš„bugï¼Œå¹¶åŠ å…¥æ•°æ®è£å‰ªä»¥é™ä½å†…å­˜å ç”¨ã€‚
    """
    required_cols = ['SKU', 'Amount', 'Qty', 'Order ID']
    if not all(col in df.columns for col in required_cols):
        raise ValueError("èšç±»åˆ†æå¤±è´¥ï¼šç¼ºå°‘å¿…è¦çš„åˆ—")

    product_agg_df = df.groupby('SKU').agg(
        total_amount=('Amount', 'sum'),
        total_qty=('Qty', 'sum'),
        order_count=('Order ID', 'nunique')
    ).reset_index()

    if product_agg_df.empty:
        return {
            "cluster_summary": [],
            "product_points": [],
            "elbow_data": [],
            "elbow_chart_json": go.Figure().to_json(),
            "scatter_3d_chart_json": go.Figure().to_json()
        }

    product_agg_df.sort_values('total_amount', ascending=False, inplace=True)

    top_k = min(len(product_agg_df), 5000)
    df_for_clustering = product_agg_df.head(top_k).copy()

    features_for_fit = df_for_clustering[['total_amount', 'total_qty', 'order_count']].astype(np.float32)
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features_for_fit)

    if features_scaled.shape[0] < 2:
        elbow_data = []
        product_agg_df['cluster'] = 0
    else:
        elbow_data = calculate_wcss_for_elbow(features_scaled)
        n_clusters = min(3, features_scaled.shape[0])
        kmeans = MiniBatchKMeans(
            n_clusters=n_clusters,
            batch_size=512,
            n_init=10,
            random_state=42
        )
        kmeans.fit(features_scaled)

        all_features = product_agg_df[['total_amount', 'total_qty', 'order_count']].astype(np.float32)
        all_features_scaled = scaler.transform(all_features)
        product_agg_df['cluster'] = kmeans.predict(all_features_scaled)

    cluster_summary_df = product_agg_df.groupby('cluster')[['total_amount', 'total_qty', 'order_count']].mean().sort_values(by='total_amount', ascending=False).reset_index()

    if not cluster_summary_df.empty:
        hot_cluster_id = cluster_summary_df.iloc[0]['cluster']
        cluster_summary_df['is_hot_cluster'] = cluster_summary_df['cluster'] == hot_cluster_id
    else:
        cluster_summary_df['is_hot_cluster'] = False

    # --- ç”Ÿæˆå›¾è¡¨å¯¹è±¡ ---
    fig_elbow = go.Figure()
    if elbow_data:
        fig_elbow.add_trace(go.Scatter(
            x=[d['k'] for d in elbow_data],
            y=[d['wcss'] for d in elbow_data],
            mode='lines+markers'
        ))
    fig_elbow.update_layout(
        title='æ‰‹è‚˜æ³•ç¡®å®šæœ€ä½³èšç±»æ•°',
        xaxis_title='èšç±»æ•°é‡ K',
        yaxis_title='ç°‡å†…å¹³æ–¹å·® (WCSS)',
        template='plotly_dark'
    )

    fig_3d = go.Figure()
    fig_3d.add_trace(go.Scatter3d(
        x=product_agg_df['total_amount'],
        y=product_agg_df['total_qty'],
        z=product_agg_df['order_count'],
        text=product_agg_df['SKU'],
        hoverinfo='x+y+z+text',
        mode='markers',
        marker=dict(
            size=5,
            color=product_agg_df['cluster'],
            colorscale='Viridis',
            opacity=0.8
        )
    ))
    fig_3d.update_layout(
        title='3Dèšç±»ç»“æœå¯è§†åŒ–',
        template='plotly_dark',
        scene=dict(
            xaxis_title='æ€»é”€å”®é¢',
            yaxis_title='æ€»é”€é‡',
            zaxis_title='è®¢å•æ•°'
        )
    )

    return {
        "cluster_summary": cluster_summary_df.to_dict(orient='records'),
        "product_points": product_agg_df.to_dict(orient='records'),
        "elbow_data": elbow_data,
        "elbow_chart_json": fig_elbow.to_json(),
        "scatter_3d_chart_json": fig_3d.to_json()
    }


def perform_sentiment_analysis(df: pd.DataFrame) -> dict:
    """
    ã€ä¼˜åŒ–ç‰ˆã€‘æƒ…æ„Ÿåˆ†æå‡½æ•°ï¼Œä½¿ç”¨å¹¶è¡Œå¤„ç†
    """
    def find_review_column(df_to_check: pd.DataFrame) -> str | None:
        priority_cols = ['reviews.text', 'review_text', 'content', 'comment', 'review']
        for p_col in priority_cols:
            if p_col in df_to_check.columns and df_to_check[p_col].dropna().astype(str).str.strip().any():
                return p_col
        
        possible_cols = [col for col in df_to_check.columns if any(key in str(col).lower() for key in ['text', 'review', 'content', 'comment'])]
        if possible_cols:
            string_cols = [col for col in possible_cols if df_to_check[col].dtype == 'object']
            if string_cols:
                return max(string_cols, key=lambda col: df_to_check[col].dropna().astype(str).str.len().mean())
        
        object_cols = df_to_check.select_dtypes(include=['object']).columns
        if not object_cols.empty:
            for col in object_cols:
                if df_to_check[col].dropna().astype(str).str.strip().any():
                    return col
        return None

    review_column_name = find_review_column(df)
    if review_column_name is None:
        raise ValueError("é”™è¯¯: æœªèƒ½åœ¨è¯„è®ºæ–‡ä»¶ä¸­æ‰¾åˆ°æœ‰æ•ˆçš„æ–‡æœ¬åˆ—ã€‚")
        
    df[review_column_name] = df[review_column_name].astype(str).dropna()
    df = df[df[review_column_name].str.strip() != 'None'].copy()
    
    analyzer = SentimentIntensityAnalyzer()
    df['sentiment'] = df[review_column_name].parallel_apply(lambda text: analyzer.polarity_scores(text)['compound'])
    
    def sentiment_to_rating(sentiment):
        if sentiment >= 0.5: return 5
        elif sentiment >= 0.05: return 4
        elif sentiment > -0.05: return 3
        elif sentiment > -0.5: return 2
        else: return 1
        
    if 'rating' not in df.columns:
        df['rating'] = df['sentiment'].apply(sentiment_to_rating)
        
    df.rename(columns={review_column_name: 'review_text'}, inplace=True)
    
    return {
        "reviews": df[['rating','review_text','sentiment']].to_dict(orient='records'),
        "average_sentiment": df['sentiment'].mean()
    }

# ==============================================================================
# Final Report Generation æ¨¡å—
# ==============================================================================

def generate_final_html_report(
    market_report: str,
    validation_summary: str,
    action_plan: str,
    sentiment_report: str | None = None,
    forecast_chart_json: str | None = None,
    clustering_data: dict | None = None,
    elbow_chart_json: str | None = None,
    scatter_3d_chart_json: str | None = None,
    basket_analysis_data: list | None = None
) -> str:
    """
    ã€æœ€ç»ˆå‡çº§ç‰ˆã€‘å°†æ‰€æœ‰åˆ†æå†…å®¹ï¼ˆåŒ…æ‹¬è´­ç‰©ç¯®åˆ†æï¼‰æ•´åˆæˆHTMLæŠ¥å‘Šã€‚
    """

    css_styles = """
    <style>
        body {
            font-family: 'Noto Sans CJK SC', 'Noto Sans SC', 'WenQuanYi Micro Hei', 'Microsoft YaHei', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #111827;
            color: #d1d5db;
        }
        .container {
            max-width: 900px;
            margin: 20px auto;
            padding: 20px;
            background-color: #1f2937;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        .header {
            text-align: center;
            border-bottom: 1px solid #374151;
            padding-bottom: 20px;
            margin-bottom: 30px;
        }
        .header h1 {
            color: #ffffff;
            font-size: 2.5em;
            margin: 0;
        }
        .header p {
            color: #9ca3af;
            font-size: 1.1em;
        }
        .section {
            background-color: #374151;
            padding: 25px;
            border-radius: 8px;
            margin-bottom: 30px;
        }
        .section h2 {
            font-size: 1.8em;
            color: #ffffff;
            border-bottom: 2px solid #4f46e5;
            padding-bottom: 10px;
            margin-top: 0;
        }
        .markdown-content h3 { font-size: 1.5em; color: #e5e7eb; }
        .markdown-content h4 { font-size: 1.2em; color: #d1d5db; }
        .markdown-content p, .markdown-content li { line-height: 1.7; }
        .markdown-content a { color: #818cf8; text-decoration: none; }
        .markdown-content a:hover { text-decoration: underline; }
        .markdown-content blockquote {
            border-left: 4px solid #4f46e5;
            padding-left: 15px;
            margin-left: 0;
            color: #9ca3af;
            font-style: italic;
        }
        .markdown-content table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        .markdown-content th, .markdown-content td {
            border: 1px solid #4b5563;
            padding: 12px;
            text-align: left;
        }
        .markdown-content th {
            background-color: #4b5563;
            color: #ffffff;
        }
        .footer {
            text-align: center;
            margin-top: 40px;
            font-size: 0.9em;
            color: #6b7280;
        }
    </style>
    """

    md_converter = markdown2.Markdown(extras=["tables", "fenced-code-blocks"])
    market_report_html = md_converter.convert(market_report)
    action_plan_html = md_converter.convert(action_plan)
    sentiment_report_html = md_converter.convert(sentiment_report) if sentiment_report else ""

    forecast_chart_html = ""
    if forecast_chart_json:
        try:
            fig = go.Figure(json.loads(forecast_chart_json))
            forecast_chart_html = fig.to_html(full_html=False, include_plotlyjs='cdn')
        except Exception:
            forecast_chart_html = "<p><i>é”€å”®é¢„æµ‹å›¾è¡¨ç”Ÿæˆå¤±è´¥ã€‚</i></p>"
    
    # æ‰‹è‚˜å›¾ï¼šç™½åº•
    elbow_chart_html = ""
    if elbow_chart_json:
        try:
            fig = go.Figure(json.loads(elbow_chart_json))
            fig.update_layout(
                template='plotly_white',
                paper_bgcolor="#ffffff",
                plot_bgcolor="#ffffff",
                font=dict(color="#111827")
            )
            elbow_chart_html = fig.to_html(full_html=False, include_plotlyjs='cdn')
        except Exception:
            elbow_chart_html = "<p><i>æ‰‹è‚˜æ³•å›¾è¡¨ç”Ÿæˆå¤±è´¥ã€‚</i></p>"
    
    # 3D å›¾ï¼šå¼ºåˆ¶ç™½åº•ï¼ˆæ›´å¼ºè¦†ç›–ï¼‰
    scatter_3d_chart_html = ""
    if scatter_3d_chart_json:
        try:
            fig = go.Figure(json.loads(scatter_3d_chart_json))
            # è¦†ç›–æ¨¡æ¿å’Œé¢œè‰²ï¼Œç¡®ä¿ä¸å— plotly_dark å½±å“
            fig.update_layout(template='plotly_white')
            fig.layout.template = 'plotly_white'  # å†æ¬¡æ˜¾å¼æŒ‡å®š
            fig.update_layout(
                paper_bgcolor="#ffffff",
                plot_bgcolor="#ffffff",
                font=dict(color="#111827"),
                scene=dict(
                    bgcolor="#ffffff",
                    xaxis=dict(
                        backgroundcolor="#ffffff",
                        gridcolor="#e5e7eb",
                        zerolinecolor="#9ca3af",
                        showbackground=True
                    ),
                    yaxis=dict(
                        backgroundcolor="#ffffff",
                        gridcolor="#e5e7eb",
                        zerolinecolor="#9ca3af",
                        showbackground=True
                    ),
                    zaxis=dict(
                        backgroundcolor="#ffffff",
                        gridcolor="#e5e7eb",
                        zerolinecolor="#9ca3af",
                        showbackground=True
                    ),
                ),
            )
            scatter_3d_chart_html = fig.to_html(full_html=False, include_plotlyjs='cdn')
        except Exception:
            scatter_3d_chart_html = "<p><i>3Dèšç±»å›¾è¡¨ç”Ÿæˆå¤±è´¥ã€‚</i></p>"

    clustering_tables_html = ""
    if clustering_data:
        try:
            summary_df = pd.DataFrame(clustering_data.get('cluster_summary', []))
            all_products_df = pd.DataFrame(clustering_data.get('product_points', []))
            
            if not summary_df.empty:
                clustering_tables_html += "<h4>å„å•†å“ç°‡ç‰¹å¾å‡å€¼</h4>"
                clustering_tables_html += summary_df.to_html(classes="markdown-content", border=0, index=False)

                hot_cluster = summary_df[summary_df['is_hot_cluster'] == True]
                if not hot_cluster.empty and not all_products_df.empty:
                    hot_cluster_id = hot_cluster.iloc[0]['cluster']
                    hot_products_df = all_products_df[all_products_df['cluster'] == hot_cluster_id].sort_values(by='total_amount', ascending=False)
                    
                    clustering_tables_html += f"<h4 style='margin-top: 20px;'>çƒ­é”€å•†å“åˆ—è¡¨ (ç°‡ {int(hot_cluster_id)})</h4>"
                    clustering_tables_html += hot_products_df[['SKU', 'total_amount', 'total_qty', 'order_count', 'cluster']].to_html(classes="markdown-content", border=0, index=False)
        except Exception:
            clustering_tables_html = "<p><i>èšç±»åˆ†æè¡¨æ ¼ç”Ÿæˆå¤±è´¥ã€‚</i></p>"
            
    basket_analysis_html = ""
    if basket_analysis_data:
        try:
            basket_df = pd.DataFrame(basket_analysis_data)
            if not basket_df.empty:
                basket_analysis_html += "<h4 style='margin-top: 20px;'>è´­ç‰©ç¯®åˆ†æ (å…³è”è§„åˆ™)</h4>"
                basket_analysis_html += "<p>æå‡åº¦(lift) > 1 è¡¨ç¤ºå¼ºå…³è”æ€§ï¼Œæ˜¯æ†ç»‘é”€å”®æˆ–äº¤å‰è¥é”€çš„ç»ä½³æœºä¼šã€‚</p>"
                basket_analysis_html += basket_df.to_html(classes="markdown-content", border=0, index=False)
        except Exception:
            basket_analysis_html = "<p><i>è´­ç‰©ç¯®åˆ†æè¡¨æ ¼ç”Ÿæˆå¤±è´¥ã€‚</i></p>"

    final_html = f"""
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>WeaveAI ç»¼åˆåˆ†ææŠ¥å‘Š</title>
        {css_styles}
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h1>ğŸ“ˆ WeaveAI ç»¼åˆåˆ†ææŠ¥å‘Š</h1>
                <p>æ•°æ®é©±åŠ¨å†³ç­–ï¼Œæ´è§å•†ä¸šæœªæ¥</p>
            </div>

            <div class="section">
                <h2>ç¬¬ä¸€éƒ¨åˆ†ï¼šå¸‚åœºæœºä¼šæ´å¯Ÿ (Insight)</h2>
                <div class="markdown-content">
                    {market_report_html}
                </div>
            </div>

            <div class="section">
                <h2>ç¬¬äºŒéƒ¨åˆ†ï¼šå†…éƒ¨æ•°æ®éªŒè¯ (Validation)</h2>
                <div class="markdown-content">
                    <h4>éªŒè¯æ‘˜è¦</h4>
                    <p>{validation_summary or "<i>æœªæä¾›éªŒè¯æ‘˜è¦ã€‚</i>"}</p>
                    
                    {forecast_chart_html}
                    
                    {'<hr style="border-color: #4b5563; margin: 30px 0;">' if (elbow_chart_html or scatter_3d_chart_html or clustering_tables_html or basket_analysis_html) else ''}
                    {elbow_chart_html}
                    {scatter_3d_chart_html}
                    {clustering_tables_html}
                    {basket_analysis_html}
                    
                    {'<hr style="border-color: #4b5563; margin: 30px 0;">' if sentiment_report_html else ''}
                    {f'<h4>AI è¯„è®ºæ·±åº¦åˆ†ææŠ¥å‘Š</h4>{sentiment_report_html}' if sentiment_report_html else ''}
                </div>
            </div>

            <div class="section">
                <h2>ç¬¬ä¸‰éƒ¨åˆ†ï¼šå­£åº¦è¡ŒåŠ¨è®¡åˆ’ (Action Plan)</h2>
                <div class="markdown-content">
                    {action_plan_html}
                </div>
            </div>
            
            <div class="footer">
                <p>æŠ¥å‘Šç”Ÿæˆäº {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
                <p>&copy; WeaveAIæ™ºèƒ½åˆ†æåŠ©æ‰‹</p>
            </div>
        </div>
    </body>
    </html>
    """
    return final_html
